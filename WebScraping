# This project helps to understand Webscraping using Python
# Webscraping is a tool for turning the unstructured data on the web into machine readable, structured data which is ready for analysis. 
# Let's scrape website that uses JavaScript Links. For this kind of website, we should use "Selenium" package
# https://www.freecodecamp.org/news/better-web-scraping-in-python-with-selenium-beautiful-soup-and-pandas-d6390592e251/
import os
import re
import pandas as pd
from bs4 import BeautifulSoup
import tabulate
from selenium import webdriver
from selenium.webdriver.chrome.webdriver import WebDriver
from selenium.webdriver.common.keys import Keys

url = "http://kanview.ks.gov/PayRates/PayRates_Agency.aspx"
driver: WebDriver = webdriver.Chrome()
driver.implicitly_wait(10)
driver.get(url)

python_button = driver.find_element_by_id('MainContent_uxLevel1_Agencies_uxAgencyBtn_33')
python_button.click()
soup_level1 = BeautifulSoup(driver.page_source, 'lxml')
datalist = []
x = 0
for link in soup_level1.find_all('a', id=re.compile("^MainContent_uxLevel2_JobTitles_uxJobTitleBtn_")):
    python_button = driver.find_element_by_id('MainContent_uxLevel2_JobTitles_uxJobTitleBtn_' + str(x))
    python_button.click()
    soup_level2 = BeautifulSoup(driver.page_source, 'lxml')
    table = soup_level2.find_all('table')[0]
    df = pd.read_html(str(table), header=0)
    datalist.append(df[0])
    driver.execute_script('window.history.go(-1)')
    x += 1
driver.quit()
result = pd.concat([pd.DataFrame(datalist[i]) for i in range(len(datalist))], ignore_index=True)
json_records = result.to_json(orient='records')
print(tabulate.tabulate(result, headers=["Employee Name", "Job Title", "Overtime Pay", "Total Gross Pay"], tablefmt='psql'))
path = os.getcwd()
f = open(path+"\\fhsu_payroll_data.json", "w")
f.write(json_records)
f.close()
